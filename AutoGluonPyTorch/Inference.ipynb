{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d83f53-4aa5-49d4-b7b3-6bccd7831b2b",
   "metadata": {},
   "source": [
    "### Deploy registered AG model in MLFlow for RT Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32478e28-6c4c-4f86-a3c4-0e31948734d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastavro\n",
      "  Downloading fastavro-1.12.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "Downloading fastavro-1.12.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: fastavro\n",
      "Successfully installed fastavro-1.12.0\n"
     ]
    }
   ],
   "source": [
    "! pip install fastavro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a575bc-12e6-477d-8f8b-d17901927ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import fastavro\n",
    "import matplotlib\n",
    "import mlflow\n",
    "import mlflow.sagemaker as mfs\n",
    "from mlflow import MlflowClient\n",
    "from sagemaker.serve import SchemaBuilder, ModelBuilder, Mode\n",
    "import sagemaker\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import mlflow.pyfunc\n",
    "import tempfile\n",
    "import os \n",
    "import io\n",
    "import boto3\n",
    "import time\n",
    "from fastavro import reader as avro_reader\n",
    "from sagemaker.serve import ModelBuilder, Mode, SchemaBuilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "183acd3d-ef66-4f3a-ac08-87921ac03ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'ag-example-timeseries'\n",
    "avro_prefix = 'avro-inf-stream'\n",
    "\n",
    "# Create S3 client\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "mlflow_uri = \"arn:aws:sagemaker:us-east-1:543531862107:mlflow-tracking-server/ag-ex-timeseries\"  # with sagemaker-mlflow plugin\n",
    "mlflow_experiment   = \"autogluon-timeseries\"\n",
    "region      = sagemaker.Session().boto_region_name\n",
    "session     = sagemaker.Session()\n",
    "role        = sagemaker.get_execution_role() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68daa353-ad31-434d-a794-a62f386b5c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fab96771253415db4a78ed5e68b7ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packaged model uploaded to: s3://ag-example-timeseries/packed-mlflow-models/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from helper_functions import package_mlflow_model\n",
    "\n",
    "mlflow_run_id = \"3ac5a4113be24a6fb64936ae5562ee54\" \n",
    "prefix = \"packed-mlflow-models\"\n",
    "\n",
    "s3_model_data_uri = package_mlflow_model(mlflow_run_id, bucket, prefix, \n",
    "                                         mlflow_tracking_arn=mlflow_uri, artifact_path='models')\n",
    "print(f\"Packaged model uploaded to: {s3_model_data_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec526c-25de-4eb2-be78-403fc814a5d0",
   "metadata": {},
   "source": [
    "### Generate dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d8d3e0f-7c8e-43db-9dea-1527bc248d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, json, time, uuid, threading, datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from fastavro import writer, parse_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab05273f-c873-4f39-bdf4-7f060fb6e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_IDS        = [\"A\", \"B\"]                        # a couple of series to demo\n",
    "FREQ_SECS       = 5                                 # new file cadence\n",
    "HORIZON         = 24  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e35a4641-f567-4359-b2fe-6c0d677a220d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gen] wrote 2 rows to s3://ag-example-timeseries/avro-inf-stream2025/09/05/224812_68a11bd5.avro\n",
      "[gen] wrote 2 rows to s3://ag-example-timeseries/avro-inf-stream2025/09/05/224817_8b662117.avro\n",
      "[gen] wrote 2 rows to s3://ag-example-timeseries/avro-inf-stream2025/09/05/224822_dae3c05d.avro\n"
     ]
    }
   ],
   "source": [
    "AVRO_SCHEMA = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"TimePoint\",\n",
    "    \"fields\": [\n",
    "        {\"name\": \"item_id\",        \"type\": \"string\"},\n",
    "        {\"name\": \"timestamp\",      \"type\": \"string\"},  # ISO 8601\n",
    "        {\"name\": \"target\",         \"type\": [\"null\", \"double\"], \"default\": None},\n",
    "        {\"name\": \"random_feature\", \"type\": [\"null\", \"double\"], \"default\": None},\n",
    "    ],\n",
    "}\n",
    "PARSED_SCHEMA = parse_schema(AVRO_SCHEMA)\n",
    "\n",
    "_stop_stream = {\"flag\": False}\n",
    "\n",
    "def _sine(i, base=10.0, noise=0.3):\n",
    "    return base + 2.0*np.sin(i/6.0) + np.random.randn()*noise\n",
    "\n",
    "def write_dummy_avro_loop():\n",
    "    i = 0\n",
    "    while not _stop_stream[\"flag\"]:\n",
    "        now = pd.Timestamp.utcnow().floor(\"s\")\n",
    "        rows = []\n",
    "        for item in ITEM_IDS:\n",
    "            rows.append({\n",
    "                \"item_id\": item,\n",
    "                \"timestamp\": (now).isoformat(),\n",
    "                \"target\": float(_sine(i + hash(item)%7)),      # last observed target (optional at inference)\n",
    "                \"random_feature\": float(np.random.randn()),    # example past/known covariate\n",
    "            })\n",
    "        buf = io.BytesIO()\n",
    "        writer(buf, PARSED_SCHEMA, rows)\n",
    "        buf.seek(0)\n",
    "        key = f\"{avro_prefix}{now.strftime('%Y/%m/%d/%H%M%S')}_{uuid.uuid4().hex[:8]}.avro\"\n",
    "        s3.upload_fileobj(buf, bucket, key)\n",
    "        print(f\"[gen] wrote {len(rows)} rows to s3://{bucket}/{key}\")\n",
    "        i += 1\n",
    "        time.sleep(FREQ_SECS)\n",
    "\n",
    "# start writer thread\n",
    "t = threading.Thread(target=write_dummy_avro_loop, daemon=True)\n",
    "t.start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a46c157-f9e7-4f0d-936f-612289ffdf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop it later with:\n",
    "_stop_stream[\"flag\"] = True\n",
    "t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0219f26a-87b0-4af6-b8d6-0bb1e650dac2",
   "metadata": {},
   "source": [
    "### Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "13a7b570-a6f2-459d-9965-df9c367fdc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "# import pandas as pd\n",
    "\n",
    "# # Helper wrappers referred earlier\n",
    "# from ag_model import (\n",
    "#     AutoGluonSagemakerEstimator,\n",
    "#     AutoGluonNonRepackInferenceModel,\n",
    "#     AutoGluonSagemakerInferenceModel,\n",
    "#     AutoGluonRealtimePredictor,\n",
    "#     AutoGluonBatchPredictor,\n",
    "# )\n",
    "# from sagemaker import utils\n",
    "# from sagemaker.serializers import CSVSerializer\n",
    "# import os\n",
    "# import boto3\n",
    "\n",
    "# role = sagemaker.get_execution_role()\n",
    "# sagemaker_session = sagemaker.session.Session()\n",
    "# region = sagemaker_session._region_name\n",
    "\n",
    "# bucket = sagemaker_session.default_bucket()\n",
    "# s3_prefix = f\"autogluon_sm/{utils.sagemaker_timestamp()}\"\n",
    "# output_path = f\"s3://{bucket}/{s3_prefix}/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "677f91c6-6c08-42ea-a34e-a04e0ff306ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ag_ts_inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ag_ts_inference.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import fastavro\n",
    "import io\n",
    "import cloudpickle\n",
    "\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "\n",
    "# Required by SageMaker for loading the model\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Loads the trained TimeSeriesPredictor from the model directory.\n",
    "    \n",
    "    Args:\n",
    "        model_dir (str): The directory where the model artifact is located.\n",
    "        \n",
    "    Returns:\n",
    "        TimeSeriesPredictor: The loaded predictor.\n",
    "    \"\"\"\n",
    "    return TimeSeriesPredictor.load(model_dir)\n",
    "\n",
    "# Required by SageMaker for inference\n",
    "def transform_fn(predictor, data, content_type, accept_type):\n",
    "    \"\"\"\n",
    "    Handles data deserialization, prediction, and serialization.\n",
    "    \n",
    "    Args:\n",
    "        predictor (TimeSeriesPredictor): The loaded Autogluon predictor.\n",
    "        data (str or bytes): The input data.\n",
    "        content_type (str): The Content-Type header of the input data.\n",
    "        accept_type (str): The Accept header requested by the client.\n",
    "        \n",
    "    Returns:\n",
    "        bytes: The serialized prediction result.\n",
    "        str: The Content-Type of the prediction result.\n",
    "    \"\"\"\n",
    "    # 1. Deserialize input\n",
    "    if content_type == \"application/json\":\n",
    "        # Handle pandas-split format from JSON\n",
    "        df = pd.read_json(io.StringIO(data), orient=\"split\")\n",
    "    elif content_type == \"application/x-avro-bytes\":\n",
    "        # Handle Avro bytes from a custom content type\n",
    "        input_stream = io.BytesIO(data)\n",
    "        reader = fastavro.reader(input_stream)\n",
    "        records = [r for r in reader]\n",
    "        df = pd.DataFrame.from_records(records)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {content_type}\")\n",
    "    \n",
    "    # 2. Perform prediction\n",
    "    ts_dataframe = TimeSeriesDataFrame(df)\n",
    "    predictions = predictor.predict(ts_dataframe)\n",
    "\n",
    "    # 3. Serialize output\n",
    "    if accept_type == \"application/json\":\n",
    "        return predictions.to_json(orient=\"split\"), accept_type\n",
    "    elif accept_type == \"text/csv\":\n",
    "        return predictions.to_csv(), accept_type\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported accept type: {accept_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216337ee-b9cd-44c0-a10f-765590c1d4b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://ag-example-timeseries/packed-mlflow-models/model.tar.gz), script artifact (.), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-543531862107/pytorch-inference-2025-09-05-22-56-59-709/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2025-09-05-22-57-36-683\n",
      "INFO:sagemaker:Creating endpoint-config with name pytorch-inference-2025-09-05-22-57-37-354\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-inference-2025-09-05-22-57-37-354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker import image_uris\n",
    "\n",
    "# --- Re-use existing setup ---\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "# Retrieve the URI for a PyTorch GPU inference image\n",
    "gpu_image_uri = image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=region,\n",
    "    version=\"2.2.0\",\n",
    "    py_version=\"py310\",\n",
    "    instance_type=\"ml.g4dn.2xlarge\",\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "\n",
    "# --- Create a SageMaker PyTorch Model instance ---\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=s3_model_data_uri,\n",
    "    role=role,\n",
    "    entry_point=\"ag_ts_inference.py\", # Path to your inference script\n",
    "    source_dir=\".\", # Directory containing the entry point script\n",
    "    image_uri=gpu_image_uri,\n",
    "    framework_version=\"2.2.0\", # Must match the framework version in the image URI\n",
    "    py_version=\"py310\", # Must match the Python version in the image URI\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# --- Deploy the model ---\n",
    "predictor = pytorch_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.2xlarge\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ab7029-5bd4-4a69-ada9-db6057ed8922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
